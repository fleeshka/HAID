services:
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    depends_on:
      - redis
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    networks:
      - app-network

    mem_limit: 2g 
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    runtime: nvidia


    entrypoint: ["/bin/bash", "-c", "ollama serve & sleep 5 && ollama run llama3:instruct && tail -f /dev/null"]
    healthcheck:
      test: curl --fail http://ollama:11434/api/tags || exit 1
      interval: 10s
      timeout: 3s
      retries: 30


  bot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: telegram-bot
    depends_on:
      - ollama
    env_file:
      - .env
    volumes:
      - ./data:/app/data 
      - ./src:/app/src 

    restart: unless-stopped
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  ollama-data:
